#!/usr/bin/env python3
"""
üñºÔ∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∫–∞–ø—á
"""

import os
import logging
from typing import Optional
from datetime import datetime

import pytesseract
from PIL import Image, ImageFilter, ImageEnhance, ImageOps
import cv2
import numpy as np

from config import (
    TESSERACT_CONFIG, TESSERACT_LANG,
    PREPROCESS_CONFIG, SCREENSHOTS_DIR
)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('ImageProcessor')

class ImageProcessor:
    """–ö–ª–∞—Å—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∫–∞–ø—á"""
    
    def __init__(self):
        self.config = PREPROCESS_CONFIG
        logger.info("‚úÖ –ü—Ä–æ—Ü–µ—Å—Å–æ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    def preprocess_image(self, image: Image.Image) -> Image.Image:
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è"""
        try:
            img = image.copy()
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ grayscale
            if img.mode != 'L':
                img = img.convert('L')
            
            # –£–≤–µ–ª–∏—á–µ–Ω–∏–µ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞
            if self.config.get('contrast', 1.0) != 1.0:
                enhancer = ImageEnhance.Contrast(img)
                img = enhancer.enhance(self.config['contrast'])
            
            # –ë–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è (—á–µ—Ä–Ω–æ-–±–µ–ª–æ–µ)
            threshold = self.config.get('threshold', 150)
            img = img.point(lambda p: 255 if p > threshold else 0)
            
            # –£–≤–µ–ª–∏—á–µ–Ω–∏–µ —Ä–µ–∑–∫–æ—Å—Ç–∏
            if self.config.get('sharpen', True):
                img = img.filter(ImageFilter.SHARPEN)
            
            # –£–±–∏—Ä–∞–µ–º —à—É–º
            if self.config.get('denoise', True):
                img = img.filter(ImageFilter.MedianFilter(size=3))
            
            # –ò–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –µ—Å–ª–∏ —Ç–µ–º–Ω—ã–π —Ç–µ–∫—Å—Ç –Ω–∞ —Å–≤–µ—Ç–ª–æ–º —Ñ–æ–Ω–µ
            pixels = np.array(img)
            white_pixels = np.sum(pixels > 128)
            black_pixels = np.sum(pixels <= 128)
            
            if black_pixels > white_pixels:
                img = ImageOps.invert(img)
            
            return img
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
            return image
    
    def recognize_text(self, image: Image.Image) -> Optional[str]:
        """–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        try:
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ Tesseract
            custom_config = f'{TESSERACT_CONFIG}'
            
            # –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ
            text = pytesseract.image_to_string(
                image,
                config=custom_config,
                lang=TESSERACT_LANG
            )
            
            # –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
            text = text.strip()
            
            # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã, –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –±—É–∫–≤—ã –∏ —Ü–∏—Ñ—Ä—ã
            text = ''.join(c for c in text if c.isalnum())
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É
            if len(text) < 3 or len(text) > 10:
                logger.warning(f"–ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
                return None
            
            logger.debug(f"–†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: '{text}'")
            return text
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞: {e}")
            return None
    
    def process_and_recognize(self, image: Image.Image) -> Optional[str]:
        """–ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è"""
        try:
            # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
            processed_img = self.preprocess_image(image)
            
            # –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ
            text = self.recognize_text(processed_img)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω —Ä–µ–∂–∏–º –æ—Ç–ª–∞–¥–∫–∏
            if text:
                self._save_debug_images(image, processed_img, text)
            
            return text
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤ process_and_recognize: {e}")
            return None
    
    def _save_debug_images(self, original: Image.Image, processed: Image.Image, text: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏"""
        try:
            os.makedirs(SCREENSHOTS_DIR, exist_ok=True)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            original.save(f"{SCREENSHOTS_DIR}/original_{timestamp}.png")
            processed.save(f"{SCREENSHOTS_DIR}/processed_{timestamp}_{text}.png")
            
            logger.debug(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {timestamp}")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç–ª–∞–¥–æ—á–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {e}")
    
    def test_recognition_from_file(self, filepath: str) -> Optional[str]:
        """–¢–µ—Å—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∏–∑ —Ñ–∞–π–ª–∞"""
        try:
            if not os.path.exists(filepath):
                logger.error(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {filepath}")
                return None
            
            image = Image.open(filepath)
            text = self.process_and_recognize(image)
            
            print(f"\nüîç –¢–ï–°–¢ –†–ê–°–ü–û–ó–ù–ê–í–ê–ù–ò–Ø:")
            print(f"–§–∞–π–ª: {filepath}")
            print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: '{text}'")
            
            return text
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {e}")
            return None

def test_recognition():
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è"""
    print("\n" + "="*60)
    print("üß™ –¢–ï–°–¢ –†–ê–°–ü–û–ó–ù–ê–í–ê–ù–ò–Ø –ö–ê–ü–ß–ò")
    print("="*60)
    
    processor = ImageProcessor()
    
    # –í–∞—Ä–∏–∞–Ω—Ç 1: –°–¥–µ–ª–∞—Ç—å —Å–∫—Ä–∏–Ω—à–æ—Ç —Å–µ–π—á–∞—Å
    print("\n1. –°–¥–µ–ª–∞—Ç—å —Å–∫—Ä–∏–Ω—à–æ—Ç —Å–µ–π—á–∞—Å")
    print("2. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª")
    
    choice = input("\n–í–∞—à –≤—ã–±–æ—Ä (1-2): ").strip()
    
    if choice == "1":
        import pyautogui
        from config import load_coordinates
        
        coords = load_coordinates()
        region = coords.get('captcha_region')
        
        if not region:
            print("‚ùå –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã!")
            return
        
        print(f"\nüì∏ –î–µ–ª–∞—é —Å–∫—Ä–∏–Ω—à–æ—Ç –æ–±–ª–∞—Å—Ç–∏: {region}")
        print("–ü–æ–¥–≥–æ—Ç–æ–≤—å—Ç–µ –∫–∞–ø—á—É –Ω–∞ —ç–∫—Ä–∞–Ω–µ...")
        input("–ù–∞–∂–º–∏—Ç–µ Enter –∫–æ–≥–¥–∞ –≥–æ—Ç–æ–≤—ã...")
        
        image = pyautogui.screenshot(region=region)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª
        timestamp = datetime.now().strftime("%H%M%S")
        filename = f"test_captcha_{timestamp}.png"
        image.save(filename)
        print(f"‚úÖ –°–∫—Ä–∏–Ω—à–æ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {filename}")
        
        # –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ
        text = processor.process_and_recognize(image)
        print(f"üìù –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: '{text}'")
        
    elif choice == "2":
        filepath = input("–í–≤–µ–¥–∏—Ç–µ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É: ").strip()
        if not filepath:
            filepath = "test_captcha.png"
        
        processor.test_recognition_from_file(filepath)
        
    else:
        print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä")

if __name__ == "__main__":
    test_recognition()
