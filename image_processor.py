#!/usr/bin/env python3
"""
üñºÔ∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∫–∞–ø—á
"""

import cv2
import numpy as np
from PIL import Image, ImageFilter, ImageEnhance
import io
import base64
from typing import Optional, Tuple
import logging

class ImageProcessor:
    """–ö–ª–∞—Å—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∫–∞–ø—á"""
    
    def __init__(self):
        self.logger = logging.getLogger('ImageProcessor')
    
    def load_image(self, image_source) -> Optional[Image.Image]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
        try:
            if isinstance(image_source, str):
                # –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
                if image_source.startswith('http'):
                    import requests
                    response = requests.get(image_source)
                    return Image.open(io.BytesIO(response.content))
                else:
                    return Image.open(image_source)
            elif isinstance(image_source, bytes):
                # –ë–∞–π—Ç—ã
                return Image.open(io.BytesIO(image_source))
            elif isinstance(image_source, Image.Image):
                # –£–∂–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ PIL
                return image_source
            elif isinstance(image_source, np.ndarray):
                # –ú–∞—Å—Å–∏–≤ numpy (OpenCV)
                return Image.fromarray(cv2.cvtColor(image_source, cv2.COLOR_BGR2RGB))
            else:
                self.logger.error(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –∏—Å—Ç–æ—á–Ω–∏–∫–∞: {type(image_source)}")
                return None
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
            return None
    
    def preprocess_captcha(self, image_source, target_size: Tuple[int, int] = (300, 100)) -> Optional[Image.Image]:
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∫–∞–ø—á–∏ –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è"""
        try:
            img = self.load_image(image_source)
            if img is None:
                return None
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ RGB –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if img.mode != 'RGB':
                img = img.convert('RGB')
            
            # 1. –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞
            img = img.resize(target_size, Image.Resampling.LANCZOS)
            
            # 2. –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ grayscale
            img = img.convert('L')
            
            # 3. –ü–æ–≤—ã—à–µ–Ω–∏–µ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞
            enhancer = ImageEnhance.Contrast(img)
            img = enhancer.enhance(2.0)  # –£–≤–µ–ª–∏—á–µ–Ω–∏–µ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞ –≤ 2 —Ä–∞–∑–∞
            
            # 4. –ü–æ–≤—ã—à–µ–Ω–∏–µ —Ä–µ–∑–∫–æ—Å—Ç–∏
            img = img.filter(ImageFilter.SHARPEN)
            
            # 5. –ë–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è (—á–µ—Ä–Ω–æ-–±–µ–ª–æ–µ)
            threshold = 150
            img = img.point(lambda p: 255 if p > threshold else 0)
            
            # 6. –£–¥–∞–ª–µ–Ω–∏–µ —à—É–º–∞ (–º–µ–¥–∏–∞–Ω–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä)
            img = img.filter(ImageFilter.MedianFilter(size=3))
            
            # 7. –ò–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –µ—Å–ª–∏ –±–µ–ª—ã–π —Ç–µ–∫—Å—Ç –Ω–∞ —á–µ—Ä–Ω–æ–º —Ñ–æ–Ω–µ
            pixels = np.array(img)
            white_pixels = np.sum(pixels > 128)
            black_pixels = np.sum(pixels <= 128)
            
            if black_pixels > white_pixels:
                img = Image.fromarray(255 - pixels)
            
            return img
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
            return None
    
    def extract_captcha_from_screenshot(self, screenshot, region: Tuple[int, int, int, int]) -> Optional[Image.Image]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ–±–ª–∞—Å—Ç–∏ –∫–∞–ø—á–∏ –∏–∑ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞"""
        try:
            if isinstance(screenshot, bytes):
                img = Image.open(io.BytesIO(screenshot))
            elif isinstance(screenshot, Image.Image):
                img = screenshot
            else:
                img = self.load_image(screenshot)
            
            if img is None:
                return None
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ–±–ª–∞—Å—Ç–∏ (x, y, width, height)
            x, y, w, h = region
            cropped = img.crop((x, y, x + w, y + h))
            
            return cropped
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –æ–±–ª–∞—Å—Ç–∏: {e}")
            return None
    
    def image_to_base64(self, image: Image.Image) -> Optional[str]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ base64"""
        try:
            buffered = io.BytesIO()
            image.save(buffered, format="PNG")
            img_str = base64.b64encode(buffered.getvalue()).decode('utf-8')
            return img_str
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –≤ base64: {e}")
            return None
    
    def save_image(self, image: Image.Image, filepath: str) -> bool:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ —Ñ–∞–π–ª"""
        try:
            image.save(filepath)
            self.logger.debug(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {filepath}")
            return True
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
            return False
    
    def compare_images(self, img1: Image.Image, img2: Image.Image, threshold: float = 0.9) -> float:
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–≤—É—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
        try:
            # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ –æ–¥–∏–Ω–∞–∫–æ–≤–æ–º—É —Ä–∞–∑–º–µ—Ä—É
            img1 = img1.resize((100, 100))
            img2 = img2.resize((100, 100))
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ –º–∞—Å—Å–∏–≤—ã
            arr1 = np.array(img1.convert('L'))
            arr2 = np.array(img2.convert('L'))
            
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            arr1 = arr1 / 255.0
            arr2 = arr2 / 255.0
            
            # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ö–æ–∂–µ—Å—Ç–∏
            similarity = np.sum(arr1 * arr2) / np.sqrt(np.sum(arr1**2) * np.sum(arr2**2))
            
            return float(similarity)
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {e}")
            return 0.0
    
    def detect_text_regions(self, image: Image.Image) -> list:
        """–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Ä–µ–≥–∏–æ–Ω–æ–≤ —Å —Ç–µ–∫—Å—Ç–æ–º"""
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ OpenCV —Ñ–æ—Ä–º–∞—Ç
            cv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
            gray = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)
            
            # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞
            thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                         cv2.THRESH_BINARY_INV, 11, 2)
            
            # –ü–æ–∏—Å–∫ –∫–æ–Ω—Ç—É—Ä–æ–≤
            contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            regions = []
            for contour in contours:
                x, y, w, h = cv2.boundingRect(contour)
                
                # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –º–∞–ª–µ–Ω—å–∫–∏—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤
                if w > 10 and h > 10 and w * h > 100:
                    regions.append((x, y, w, h))
            
            return regions
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è —Ä–µ–≥–∏–æ–Ω–æ–≤: {e}")
            return []
    
    def remove_background(self, image: Image.Image) -> Optional[Image.Image]:
        """–£–¥–∞–ª–µ–Ω–∏–µ —Ñ–æ–Ω–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ –º–∞—Å—Å–∏–≤
            img_array = np.array(image)
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ HSV –¥–ª—è –≤—ã–¥–µ–ª–µ–Ω–∏—è —Ü–≤–µ—Ç–∞
            hsv = cv2.cvtColor(img_array, cv2.COLOR_RGB2HSV)
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –º–∞—Å–∫–∏ –¥–ª—è –±–µ–ª–æ–≥–æ —Ñ–æ–Ω–∞
            lower_white = np.array([0, 0, 200])
            upper_white = np.array([180, 30, 255])
            mask = cv2.inRange(hsv, lower_white, upper_white)
            
            # –ò–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–∞—Å–∫–∏
            mask = cv2.bitwise_not(mask)
            
            # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –º–∞—Å–∫–∏
            result = cv2.bitwise_and(img_array, img_array, mask=mask)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –æ–±—Ä–∞—Ç–Ω–æ –≤ PIL
            result_image = Image.fromarray(result)
            
            return result_image
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —Ñ–æ–Ω–∞: {e}")
            return None

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    logging.basicConfig(level=logging.INFO)
    
    processor = ImageProcessor()
    
    # –ü—Ä–∏–º–µ—Ä –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    test_image_path = "test_captcha.png"  # –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ –ø—É—Ç—å –∫ —Ç–µ—Å—Ç–æ–≤–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
    
    try:
        processed = processor.preprocess_captcha(test_image_path)
        if processed:
            processed.save("processed_captcha.png")
            print("‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ")
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ base64
            base64_str = processor.image_to_base64(processed)
            if base64_str:
                print(f"Base64 (–ø–µ—Ä–≤—ã–µ 100 —Å–∏–º–≤–æ–ª–æ–≤): {base64_str[:100]}...")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
